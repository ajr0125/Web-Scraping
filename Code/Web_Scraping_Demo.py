# -*- coding: utf-8 -*-
"""Web Scraping Demo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16Dbw167-6ePcNlR4EN42hyAjIk-L0KOy
"""

# Web Scraping Imports
from bs4 import BeautifulSoup
import requests

# Set the URL for the webpage containing Largest US Companies by Revenue
url = 'https://en.wikipedia.org/wiki/List_of_largest_companies_in_the_United_States_by_revenue'

# Send an HTTP GET request to the URL to retrieve the page content
page = requests.get(url)

# Parse the retrieved page content with BeautifulSoup, specifying 'html' as the parser format
soup = BeautifulSoup(page.text, 'html')

print(soup)

# Find first table element
soup.find('table')

# Find all <table> elements on the page and select the second one (index [1])
soup.find_all('table')[1]

# Single out the specific table we are looking for using its class id
soup.find('table', class_ = 'wikitable sortable')

# Assigning desired table for use
table = soup.find_all('table')[1]

print(table)

# Find table headers
world_titles = table.find_all('th')

print(world_titles)

# Create a list to hold the text content of each header element in world_titles.
# For each title (header), extract its text, remove any leading/trailing whitespace,
# and add it to the list
world_table_titles = [title.text.strip() for title in world_titles]

print(world_table_titles)

# Import pandas for dataframe usage
import pandas as pd

df = pd.DataFrame(columns = world_table_titles)

print(df)

# Create dataframe with previously stored column titles
column_data = table.find_all('tr')

# Loop through each row in column_data, starting from the second row (index 1)
# This skips the first row, which typically contains column headers.
for row in column_data[1:]:
    # Find all <td> elements within the current row
    row_data = row.find_all('td')
    # Extract and clean the text from each <td> element in the row, removing any extra whitespace
    individual_row_data = [data.text.strip() for data in row_data]
    # Check if the number of columns in match_table_titles matches the number of data points in the row
    length = len(df)
    # Add the row data to the DataFrame
    df.loc[length] = individual_row_data

print(df)

# Export df_men as a CSV file
df.to_csv('LargestUSCompaniesByRevenue.csv', index=False)